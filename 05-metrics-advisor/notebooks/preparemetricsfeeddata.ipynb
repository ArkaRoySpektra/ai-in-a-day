{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook will guide you through a list of steps needed to prepare a time series-based dataset containing JSON files to be fed into the Metrics Advisor workspace. Each JSON file will contain daily data representing the count of COVID positive cases by age group."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's import the requires libraries and namespaces."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pandas.io.json import json_normalize\n",
        "import numpy as np\n",
        "import datetime\n",
        "import os, shutil\n",
        "import math\n",
        "import timeit\n",
        "from io import StringIO\n",
        "import re\n",
        "import urllib.request, json\n",
        "\n",
        "print(\"pandas version: {} numpy version: {}\".format(pd.__version__, np.__version__))\n",
        "\n",
        "import os\n",
        "import azureml.core\n",
        "from azureml.core import Workspace, Datastore, Dataset\n",
        "# Check core SDK version number\n",
        "print(\"azureml SDK version:\", azureml.core.VERSION)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1644847295511
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replace the `<BLOBSTORAGE_ACCOUNT_NAME>` and `<BLOBSTORAGE_ACCOUNT_KEY>` values below with the values you have noted down on a previous step."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Provide values for the existing blob storage account name and key\n",
        "blob_account_name = \"<BLOBSTORAGE_ACCOUNT_NAME>\"\n",
        "blob_account_key = \"<BLOBSTORAGE_ACCOUNT_KEY>\"\n",
        "blob_datastore_name='covid_datastore' # Name of the datastore to workspace\n",
        "container_name = \"jsonmetrics\" # Name of Azure blob container"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1644847295587
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connect to the Azure Machine Learning workspace and register the `covid_datastore` container in the workspace. This is the place where the input data for Metrics Advisor will be saved."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\n",
        "\n",
        "#register the datastore where the Metrics Advisor data feed will be generated\n",
        "blob_datastore = Datastore.register_azure_blob_container(\n",
        "    workspace=ws, \n",
        "    datastore_name=blob_datastore_name, \n",
        "    container_name=container_name, \n",
        "    account_name=blob_account_name,\n",
        "    account_key=blob_account_key)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1644847297146
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the COVID-19 case surveillance dataset.\n",
        "\n",
        "Inspect the first 10 rows in the dataset."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\n",
        "    'https://aiinadayaiw.blob.core.windows.net/aiinaday/' +\n",
        "    'COVID-19_Case_Surveillance_Public_Use_Data_v2.csv')\n",
        "df.head(10)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1644847441127
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare the timestamp column to match the format required by the Metrics Advisor ingestion process."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df['cdc_report_dt']=pd.to_datetime(df['cdc_report_dt']) + (pd.to_timedelta(11, unit='D'))\n",
        "df['datekey'] =  pd.to_datetime(df['cdc_report_dt']).dt.strftime('%Y-%m-%d')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1644847764070
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Group data by date, age group, and hospitalization status."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "dfgroup = df.groupby(['datekey','age_group','hosp_yn']).size().to_frame()\n",
        "dfgroup.rename(columns={0: 'count'}, inplace=True)\n",
        "dfgroup.head(10)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1644848070930
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reset the index hierarchical index resulting from the group by process to flatten the dataset."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "dfflat = dfgroup.reset_index()\n",
        "dfflat.head(10)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1644848078206
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the list of dates for which data is available in the original dataset."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "dates = df['datekey'].unique()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1644848084774
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the daily JSON files to be ingested by Metrics Advisor."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists('covid_age_hosp'):\n",
        "    shutil.rmtree('covid_age_hosp')\n",
        "    \n",
        "os.mkdir('covid_age_hosp')\n",
        "\n",
        "for row in dates:\n",
        "    print(row)\n",
        "    is_date = dfflat['datekey']==row\n",
        "    df_date = dfflat[is_date]\n",
        "    resultJSON = df_date.to_json(orient='records', date_format='%Y-%m-%d')\n",
        "    filename_processed_json =  f'covid_age_hosp/{row}.json'\n",
        "    with open(filename_processed_json, 'w') as f:\n",
        "        f.write(resultJSON)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1644848217147
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload the local folder containing the generated JSON files to the blob storage container."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "blob_datastore.upload('./covid_age_hosp', \n",
        "                 target_path = '', \n",
        "                 overwrite = True, \n",
        "                 show_progress = True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1644848387569
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3-azureml"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
